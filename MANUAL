To compute ST_TTs

- Run ST Pipeline for each dataset of the same sample (Run)
- Take the bed file with counts and decide how to filter it out 
  (include or not non annotated transcripts and remove or not features outside tissue) 
  To remove non annotated simply use a grep (__no_feature) 
  To remove features outside the tissue use the script filterSTData.py 
  with a selection file exported from the ST viewer on the same dataset. 
- Make sure that the selection made in the viewer is from the exactly 
  the same run as the original bed file. 
  Otherwise update the counts by using convert_selection_counts.py
- Run countClusters.py with several values of the min_distance and min_value parameters to generate ST_TTs.
  Then look in Zenbu and choose the parameters that fit the best 
  (use clusters_to_igv.py to add to zenbu the ctts files 
  and compute_bed_counts.sh to transform the reads.bed (annotation file used in the ST Pipeline) and also add it to Zenbu). 
- Run tag_clusters_to_table.py on the optimal output from the step before for each 
  sample. So we obtain a counts table for each sample.                                                

To do un-supervised learning

- Run the unsupervised.py script (you need to know how many clusters you want to find beforehand)
  Basically you need :
    - Path to a data frame with counts (spots as rows and gene as columns)
    - Clustering algorithm to use
    - Dimensionality reduction algorithm to use
    - Image of the tissue (optional)
    - Alignment matrix to transform spot coordinates to image pixel coordinates (optional)
    
To do supervised learning

- Run supervised.py with the output from unsupervised.py
  You need :
    - A train set (the normalized counts)
    - A test set (the normalized counts)
    - Annotation for training (CLASS X Y)
    - Annotation for testing if available (CLASS X Y)
    - Image of the tissue (optional)
    - Alignment matrix to transform spot coordinates to image pixel coordinates (optional)    
